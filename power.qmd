# Power {#sec-power}

Knowledge is power. That is, it grounds an ability to do things. What things? Not, typically, bodily movements. If Lupin knows the passcode for the phone, he can unlock the phone. But even without that knowledge, he could make the bodily movement of typing in 220348 or whatever the passcode was. What power does he get from knowing the code is 220348? He gets the ability to deliberately unlock the phone. He gets the ability to unlock the phone by typing 220348, and this not be a lucky guess, but a rational action. Knowledge makes rational action possible. That's why it is powerful. That's what its power consists in. That's why the NyƒÅya philosophers were right to base anti-sceptical arguments on the possibility of rational action. Knowledge matters in everyday life; it explains why we have the power we have to act rationally.^[The story I'm telling in this paragraph deliberately echoes the view that ability modals do not express possibility but necessity [@MandelkernEtAl2017]. To say Lupin can unlock the phone is not to say he might unlock the phone - anyone might unlock it hitting random numbers - it's to say he has a method that would unlock the phone if deployed.]

But it turns out to be surprisingly hard to articulate the magnitude of that power. One might want to say that knowing that _p_ makes rational any action whatsoever that would make sense if _p_ could be taken as given. This, as we've seen many times over, can't be right. If it were right it would entail either that some actions that seem horribly reckless are in fact rational, or that an absurd form of scepticism is true, and almost no actions are in fact rational. If our pre-theoretic judgments of which actions are rational is even close to being right, there must be limits to the power of knowledge.

Are those limits sensitive to the interests of the would-be knower, or are they independent of those interests? I've argued that they are sensitive to the knower's interests, against what I called the orthodox view that they are not. There are two primary reasons I've given for this.

One reason is that the interest-relative answer, unlike the orthodox answer, makes it clear why the boundary between knowledge and non-knowledge matters. On the interest-relative view, the boundary between knowledge and non-knowledge is philosophically and practically significant. On the orthodox view, it's like the boundary between heavy things and non-heavy things. How heavy something is matters a lot; just which side of the heavy/non-heavy boundary it falls on does not. 

According to orthodoxy, to know something is to have enough power to use that knowledge to act rationally in, you know, a wide enough range of cases. How wide? It's sort of wide enough. Why is it this range rather than some other? Oh, no good reason. We just talk that way, and it's the job of epistemologists to explain why we do. No, not explain - because it's arbitrary and inexplicable. It's to describe the limits, limits which are ultimately quite arbitrary. This is no good at all. The heterodox interest-relative view has a better answer. The limits are set just where they need to be to make it true that what this person knows rationalises the actions that it should in fact rationalise.

A second reason for favoring the interest-relative view is that it makes some core principles of action theory and decision theory turn out to be correct, while the orthodox view makes them not quite right. Here are the (versions of the)  principles I have in mind.

Means-End Rationality
:    If _X_ should be aiming for end _E_, and _X_ knows both that action _A_ is the only means to end _E_, and that _A_ will indeed lead to end _E_, to then _X_ should intend to perform _A_.

Strict Dominance Reasoning
:    If _X_ has to choose between _A_ and _B_, and there is some partition _P_ of a space of possibilities such that _X_ knows both that precisely one member of _P_ is actual, and that conditional on each member of _P_, _A_ is better than _B_, then _X_ should prefer _A_ to _B_.

Given orthodoxy, neither of these can be correct. In each case, _X_ might know that _A_ will lead to a good outcome, but it also be sufficiently probable that _A_ will lead to a disastrous outcome that it is irrational for _X_ to choose _A_. That's absurd, and so we should reject orthodoxy. The interest-relative view makes these, and any number of related principles, turn out unrestrictedly true.^[Note that it's not much help to say that the principles are approximately true on the orthodox picture. In game theory we want to be able to iterate principles like this, and approximately true principles can't be applied iteratively.]

If these are the two reasons for adopting an interest-relative view, the appeal of some kind of contextualist version of an interest-invariant view should be clear. The contextualist can, and does, say that there is something special about the boundary between knowledge and non-knowledge. When one say that someone knows something, one means (more or less) that their evidence for that thing is good enough for one's own purposes. Any speaker of the language can truly say, "When I use 'knows', it means what I need it to mean, neither more nor less." We could quibble here, but that's something like a solution to the problem of arbitrariness.

The problems come with the principles like Means-End Rationality and Strict Dominance Reasoning. These are both false on contextualist views. Contextualists are aware of this fact, and say that they have something nearly as good: a meta-linguistic replacement. Both principles are true if we replace talk about what _X_ knows with talk about what _X_ can truly self-predicate 'knowledge' of. It doesn't matter whether _X_ knows that _A_ will lead to end _E_, but whether _X_ can say the words _I know that performing A will lead to end E_. But it's absurd to think that fundamental principles of rationality should make reference to a particular language, e.g., English, like this. So contextualism cannot get us out of this jam. This is not to say that contextualism is false. Maybe there are other reasons to believe in contextualism. It might be supported by general principles about the way that names behave in attitude ascriptions. Or it might be a consequence of the view that 'knows' is polysemous, a view I suggested back in [chapter @sec-inquiry]. Or it might be supported by reflection on cases where people talk about others with lower evidential needs than their own. I don't take a stance on these questions here; I'm just arguing that contextualism doesn't save orthodoxy.

But all these benefits of the interest-relative view are of no use if the view has even worse defects. And most of this book has involved pushing back against some of the alleged defects of the view. In some case, I've avoided possible criticisms by adopting a form of interest-relative epistemology that doesn't allow the criticisms to take hold. Many existing critiques of interest-relative epistemology focus on forms of the view where being in a 'high stakes' situation is relevant to what one knows. Since my version of the view doesn't have stakes play a direct role, those criticisms don't have any bite. Other critiques target a part-time version of interest-relative epistemology, where some but not all key notions are interest-relative. I used to endorse such a part-time interest-relative theory, but eventually decided that the criticisms were decisive. 

Still, many criticisms do need replies, and that's taken up much of the book. So in [chapter @sec-belief] I replied to (successful) criticisms of how I'd formally handled knowledge of propositions that are not relevant to the thinker's current inquiries. In [chapter @sec-inquiry] I replied to arguments that started with the observation that it sometimes seems right to double check things that we know. And in [chapter @sec-ties] I replies to arguments based on versions of interest-relative epistemology (including the version I'd previously endorsed) handled choices between nearly indistinguishable options.

Many criticisms of interest-relative epistemology do not turn on detailed engagement with how the view handles this or that case, but on the very idea of interests being relevant to epistemology. One way you see this is with arguments that just start from the implausibility of two people who are alike in evidence differing with respect to knowledge. But you also see it in the surprisingly common position in the literature that there is some extra large burden of proof on defenders of interest-relativity. It seems to be a common presupposition that unless there is a super compelling argument that knowledge is interest-relative, we should reject the idea that it is, even if there is no equally compelling argument against the idea. I'm in general very sceptical of burden of proof arguments; it always looks like an attempt to win by bribing the umpires. But there is extra reason to be sceptical here. The reason I so belabored the point in [chapter @sec-changes] about how many things we know knowledge is sensitive to, was to show that it is really very hard to make any sweeping generalisations about what might matter to knowledge. 

We've known since 1963 (if not many centuries before) that knowledge depends on more than just the evidential basis of the thing purportedly known. Since then there has been a dizzying array of proposals about what else knowledge might depend on. And on reflection, many of these proposals have been very plausible. This book aims to defend one such proposal, that knowledge depends on interests. In particular, how much evidential support one needs to have knowledge depends on what inquiries one is, and should be, engaged in. Given the tight relationships between knowledge and rational action, adding this to the vast list of things knowledge is sensitive to should not be surprising.

